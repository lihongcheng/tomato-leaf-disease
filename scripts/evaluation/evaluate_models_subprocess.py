#!/usr/bin/env python3
"""
å­è¿›ç¨‹TFLiteæ¨¡å‹è½¬æ¢ä¸è¯„ä¼°è„šæœ¬
é€šè¿‡å­è¿›ç¨‹éš”ç¦»é¿å…TensorFlowæ®µé”™è¯¯
ç”¨äºç”Ÿæˆè®ºæ–‡Table5.5 - TFLiteè½¬æ¢åæ¨¡å‹å¯¹æ¯”æ•°æ®
"""

import os
import time
import subprocess
import json
import tempfile
import torch
import torch.nn as nn
import torchvision.models as tv_models
import timm
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from tabulate import tabulate
from data_process import DataProcessor, PlantDataset, Config
from attention_module import CoordAtt

# é…ç½®å‚æ•°
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 1  # æ¨¡æ‹Ÿç§»åŠ¨ç«¯å•å¼ æ¨ç†
NUM_WORKERS = 4
IMAGE_SIZE = (224, 224)

# æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
CHECKPOINTS = {
    "MobileNetV3_small": "./checkpoints/MobileNetV3/best_checkpoint.pth",
    "EfficientNet_B0": "./checkpoints/efficientnetb0/best_checkpoint.pth", 
    "MobileNetV1": "./checkpoints/MobileNetV1/best_checkpoint.pth",
    "ShuffleNetV2_x1_0": "./checkpoints/shufflenetV2/best_checkpoint.pth",
    "MobileNetV3_Attention":"./checkpoints/MobileNetV3_Attention/best_checkpoint.pth",
}

# TFLiteè¾“å‡ºç›®å½•
TFLITE_DIR = "./tflite_models"
os.makedirs(TFLITE_DIR, exist_ok=True)

class MobileNetV3WithAttention(nn.Module):
    """å¸¦æ³¨æ„åŠ›æœºåˆ¶çš„MobileNetV3æ¨¡å‹"""
    def __init__(self, num_classes=11, attention_channels=24):
        super(MobileNetV3WithAttention, self).__init__()
        self.mobilenet = tv_models.mobilenet_v3_small(weights=None)
        self.features = self.mobilenet.features
        self.attention = CoordAtt(inp=attention_channels, oup=attention_channels)
        self.avgpool = self.mobilenet.avgpool
        self.classifier = nn.Sequential(
            nn.Linear(576, 1024),
            nn.Hardswish(inplace=True),
            nn.Dropout(p=0.2, inplace=True),
            nn.Linear(1024, num_classes),
        )

    def forward(self, x):
        x = self.features[:4](x)
        x = self.attention(x)
        x = self.features[4:](x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

def load_pytorch_model(name, num_classes):
    """åŠ è½½PyTorchæ¨¡å‹"""
    if name == "MobileNetV3_small":
        model = tv_models.mobilenet_v3_small(weights=None)
        model.classifier[3] = nn.Linear(1024, num_classes)
    elif name == "EfficientNet_B0":
        model = tv_models.efficientnet_b0(weights=None)
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(in_features, num_classes)
    elif name == "MobileNetV1":
        model = timm.create_model('mobilenetv1_100', pretrained=False)
        in_features = model.get_classifier().in_features
        model.classifier = nn.Linear(in_features, num_classes)
    elif name == "ShuffleNetV2_x1_0":
        model = tv_models.shufflenet_v2_x1_0(weights=None)
        in_features = model.fc.in_features
        model.fc = nn.Linear(in_features, num_classes)
    elif name == "MobileNetV3_Attention":
        # ä½¿ç”¨è‡ªå®šä¹‰å¸¦æ³¨æ„åŠ›æœºåˆ¶æ¨¡å‹
        model = MobileNetV3WithAttention(num_classes=num_classes)
    else:
        raise ValueError(f"Unknown model: {name}")
    
    return model

def count_parameters(model):
    """è®¡ç®—æ¨¡å‹å‚æ•°é‡"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def estimate_model_size_mb(model):
    """ä¼°ç®—æ¨¡å‹å¤§å°ï¼ˆMBï¼‰"""
    param_size = 0
    buffer_size = 0
    
    for param in model.parameters():
        param_size += param.nelement() * param.element_size()
    
    for buffer in model.buffers():
        buffer_size += buffer.nelement() * buffer.element_size()
    
    model_size = param_size + buffer_size
    return model_size / (1024 * 1024)

def get_checkpoint_size_mb(checkpoint_path):
    """è·å–æ£€æŸ¥ç‚¹æ–‡ä»¶å¤§å°"""
    if os.path.exists(checkpoint_path):
        return os.path.getsize(checkpoint_path) / (1024 * 1024)
    return 0.0

def measure_inference_time(model, test_loader, num_samples=100):
    """æµ‹é‡æ¨ç†æ—¶é—´"""
    model.eval()
    inference_times = []
    sample_count = 0
    
    with torch.no_grad():
        for images, labels in test_loader:
            if sample_count >= num_samples:
                break
                
            images = images.to(DEVICE)
            batch_size = images.shape[0]
            
            # é€å¼ æµ‹é‡ï¼ˆæ¨¡æ‹Ÿç§»åŠ¨ç«¯åœºæ™¯ï¼‰
            for i in range(batch_size):
                if sample_count >= num_samples:
                    break
                    
                single_image = images[i:i+1]
                
                # é¢„çƒ­
                for _ in range(3):
                    _ = model(single_image)
                
                # å®é™…æµ‹é‡
                torch.cuda.synchronize() if torch.cuda.is_available() else None
                start_time = time.time()
                _ = model(single_image)
                torch.cuda.synchronize() if torch.cuda.is_available() else None
                end_time = time.time()
                
                inference_times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
                sample_count += 1
    
    return {
        'mean_ms': np.mean(inference_times),
        'std_ms': np.std(inference_times),
        'min_ms': np.min(inference_times),
        'max_ms': np.max(inference_times),
        'samples': len(inference_times)
    }

def create_tflite_converter_script():
    """åˆ›å»ºç‹¬ç«‹çš„TFLiteè½¬æ¢è„šæœ¬"""
    script_content = '''#!/usr/bin/env python3
import os
import sys
import json
import warnings
import time

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
warnings.filterwarnings('ignore')

def safe_import_tf():
    try:
        import tensorflow as tf
        tf.config.threading.set_intra_op_parallelism_threads(1)
        tf.config.threading.set_inter_op_parallelism_threads(1)
        tf.config.set_visible_devices([], 'GPU')
        return tf
    except Exception as e:
        print(f"TensorFlow import failed: {e}")
        return None

def convert_onnx_to_tflite(onnx_path, tflite_path):
    tf = safe_import_tf()
    if tf is None:
        return False, "TensorFlow not available"
    
    try:
        import onnx
        from onnx_tf.backend import prepare
        
        # 1. éªŒè¯ONNXæ¨¡å‹æœ‰æ•ˆæ€§
        onnx_model = onnx.load(onnx_path)
        onnx.checker.check_model(onnx_model)
        
        # 2. åˆ›å»ºä¸´æ—¶ç›®å½•
        import tempfile
        with tempfile.TemporaryDirectory() as tmpdir:
            savedmodel_path = os.path.join(tmpdir, "saved_model")
            
            # 3. ä½¿ç”¨ onnx-tf å°†ONNXè½¬æ¢ä¸ºSavedModel
            tf_rep = prepare(onnx_model)
            tf_rep.export_graph(savedmodel_path)
            
            # 4. è½¬æ¢ä¸ºTFLite
            converter = tf.lite.TFLiteConverter.from_saved_model(savedmodel_path)
            converter.optimizations = [tf.lite.Optimize.DEFAULT]
            converter.target_spec.supported_ops = [
                tf.lite.OpsSet.TFLITE_BUILTINS,
                tf.lite.OpsSet.SELECT_TF_OPS
            ]
            tflite_model = converter.convert()
            
            with open(tflite_path, 'wb') as f:
                f.write(tflite_model)
        
        return True, f"Success: {os.path.getsize(tflite_path)} bytes"
        
    except Exception as e:
        return False, f"Conversion failed: {str(e)}"

def _preprocess_image_rgb(image_path, size=(224, 224)):
    from PIL import Image
    import numpy as np
    img = Image.open(image_path).convert('RGB')
    img = img.resize(size, resample=Image.BILINEAR)
    arr = np.asarray(img).astype('float32') / 255.0  # HWC, [0,1]
    # Normalize with ImageNet mean/std
    mean = np.array([0.485, 0.456, 0.406], dtype='float32')
    std = np.array([0.229, 0.224, 0.225], dtype='float32')
    arr = (arr - mean) / std
    arr = np.transpose(arr, (2, 0, 1))  # CHW
    arr = arr.reshape(1, 3, size[0], size[1])
    return arr.astype('float32')


def _wilson_interval(k, n, z=1.96):
    if n == 0:
        return 0.0, 0.0
    p = k / n
    denom = 1 + (z*z)/n
    center = (p + (z*z)/(2*n)) / denom
    margin = (z * ((p*(1-p)/n + (z*z)/(4*n*n)) ** 0.5)) / denom
    return max(0.0, center - margin), min(1.0, center + margin)


def evaluate_tflite_model(tflite_path, test_index_path):
    tf = safe_import_tf()
    if tf is None:
        return None, "TensorFlow not available"
    
    try:
        import numpy as np
        with open(test_index_path, 'r') as f:
            index = json.load(f)
        image_paths = index['image_paths']
        true_labels = index['labels']
        
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        predictions = []
        times = []
        
        for i, img_path in enumerate(image_paths):
            input_data = _preprocess_image_rgb(img_path)
            # æ ¹æ®é‡åŒ–ç±»å‹è°ƒæ•´è¾“å…¥
            if input_details[0]['dtype'] == np.uint8:
                scale, zero_point = input_details[0]['quantization']
                if scale != 0:
                    input_data = input_data / scale + zero_point
                input_data = np.clip(input_data, 0, 255).astype(np.uint8)
            else:
                input_data = input_data.astype(np.float32)
            
            interpreter.set_tensor(input_details[0]['index'], input_data)
            start = time.time()
            interpreter.invoke()
            elapsed = time.time() - start
            times.append(elapsed)
            output = interpreter.get_tensor(output_details[0]['index'])
            predictions.append(int(np.argmax(output, axis=1)[0]))
        
        # ç»Ÿè®¡
        correct = int(np.sum(np.array(predictions) == np.array(true_labels)))
        n = len(true_labels)
        accuracy = correct / n if n > 0 else 0.0
        ci_low, ci_high = _wilson_interval(correct, n, z=1.96)
        avg_ms = float(np.mean(times) * 1000.0) if len(times) > 0 else 0.0
        
        return {
            'accuracy': accuracy,
            'accuracy_ci_low': ci_low,
            'accuracy_ci_high': ci_high,
            'avg_inference_time_ms': avg_ms,
            'throughput_fps': 1000.0 / avg_ms if avg_ms > 0 else 0.0,
            'total_samples': n
        }, None
        
    except Exception as e:
        return None, str(e)

if __name__ == "__main__":
    import time
    
    command = sys.argv[1]
    
    if command == "convert":
        onnx_path = sys.argv[2]
        tflite_path = sys.argv[3]
        success, message = convert_onnx_to_tflite(onnx_path, tflite_path)
        result = {"success": success, "message": message}
        print(json.dumps(result))
        
    elif command == "evaluate":
        tflite_path = sys.argv[2]
        test_index_path = sys.argv[3]
        result, error = evaluate_tflite_model(tflite_path, test_index_path)
        if result:
            print(json.dumps({"success": True, "result": result}))
        else:
            print(json.dumps({"success": False, "error": error}))
'''
    
    script_path = os.path.join(TFLITE_DIR, "tflite_converter.py")
    with open(script_path, 'w') as f:
        f.write(script_content)
    os.chmod(script_path, 0o755)
    return script_path

def convert_to_tflite_subprocess(pytorch_model, model_name, test_loader, use_full_testset=True):
    """é€šè¿‡å­è¿›ç¨‹å®‰å…¨åœ°è½¬æ¢å’Œè¯„ä¼°TFLiteæ¨¡å‹"""
    converter_script = create_tflite_converter_script()
    
    # 1. å…ˆå¯¼å‡ºONNXï¼ˆåœ¨ä¸»è¿›ç¨‹ä¸­ï¼Œè¿™éƒ¨åˆ†æ˜¯å®‰å…¨çš„ï¼‰
    # ç¡®ä¿æ¨¡å‹å’Œè¾“å…¥åœ¨åŒä¸€è®¾å¤‡ä¸Š
    pytorch_model.eval()
    
    # å°†æ¨¡å‹ç§»åˆ°CPUè¿›è¡ŒONNXå¯¼å‡ºï¼ˆé¿å…è®¾å¤‡ä¸åŒ¹é…ï¼‰
    model_device = next(pytorch_model.parameters()).device
    pytorch_model_cpu = pytorch_model.cpu()
    dummy_input = torch.randn(1, 3, 224, 224)  # CPU tensor
    onnx_path = os.path.join(TFLITE_DIR, f"{model_name}.onnx")
    
    try:
        print(f"ğŸ”„ å¯¼å‡º {model_name} ä¸ºONNXæ ¼å¼...")
        torch.onnx.export(
            pytorch_model_cpu,
            dummy_input,
            onnx_path,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}
        )
        print(f"âœ… {model_name} ONNXå¯¼å‡ºæˆåŠŸ")
        
        # å°†æ¨¡å‹ç§»å›åŸè®¾å¤‡
        pytorch_model.to(model_device)
    except Exception as e:
        print(f"âŒ ONNXå¯¼å‡ºå¤±è´¥: {e}")
        # ç¡®ä¿æ¨¡å‹ç§»å›åŸè®¾å¤‡
        pytorch_model.to(model_device)
        return None, None
    
    # 2. å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆç”¨äºTFLiteè¯„ä¼°ï¼‰
    sample_count = 0
    
    if use_full_testset:
        # ä½¿ç”¨å…¨æµ‹è¯•é›†
        max_samples = float('inf')  # ä¸é™åˆ¶æ ·æœ¬æ•°é‡
        print(f"ğŸ“Š å‡†å¤‡å…¨æµ‹è¯•é›†æ•°æ®ç”¨äºTFLiteè¯„ä¼°...")
    else:
        # ä»…ä½¿ç”¨50ä¸ªæ ·æœ¬ï¼ˆå‘åå…¼å®¹ï¼‰
        max_samples = 50
        print(f"ğŸ“Š å‡†å¤‡{max_samples}ä¸ªæ ·æœ¬ç”¨äºTFLiteè¯„ä¼°...")
    
    # ä»Datasetçš„metaæ„é€ ç»å¯¹è·¯å¾„ä¸æ ‡ç­¾ç´¢å¼•ï¼Œé¿å…å°†æ•´å¹…å›¾åƒåºåˆ—åŒ–åˆ°ç£ç›˜
    dataset = test_loader.dataset
    image_paths = []
    labels = []
    for idx in range(len(dataset.meta)):
        if sample_count >= max_samples:
            break
        rec = dataset.meta.iloc[idx]
        rel_path = rec['aug_path'] if rec['is_augmented'] else rec['orig_path']
        full_path = os.path.join(Config.DATA_ROOT, rel_path)
        image_paths.append(full_path)
        labels.append(int(dataset.class_map[rec['class']]))
        sample_count += 1
    
    print(f"ğŸ“Š å®é™…å‡†å¤‡äº†{sample_count}ä¸ªæµ‹è¯•æ ·æœ¬ç”¨äºTFLiteè¯„ä¼°")
    
    test_index = {
        'image_paths': image_paths,
        'labels': labels
    }
    test_index_path = os.path.join(TFLITE_DIR, f"{model_name}_test_index.json")
    with open(test_index_path, 'w') as f:
        json.dump(test_index, f)
    
    # 3. é€šè¿‡å­è¿›ç¨‹è½¬æ¢ONNXåˆ°TFLite
    tflite_path = os.path.join(TFLITE_DIR, f"{model_name}.tflite")
    
    try:
        print(f"ğŸ”„ é€šè¿‡å­è¿›ç¨‹è½¬æ¢ {model_name} ä¸ºTFLite...")
        result = subprocess.run([
            'python', converter_script, 'convert', onnx_path, tflite_path
        ], capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            try:
                out = result.stdout.strip()
                last_line = out.splitlines()[-1] if '\n' in out else out
                convert_result = json.loads(last_line)
                if convert_result['success']:
                    print(f"âœ… {model_name} TFLiteè½¬æ¢æˆåŠŸ")
                    tflite_size_mb = os.path.getsize(tflite_path) / (1024 * 1024)
                else:
                    print(f"âŒ {model_name} TFLiteè½¬æ¢å¤±è´¥: {convert_result['message']}")
                    return None, None
            except:
                print(f"âŒ {model_name} è½¬æ¢ç»“æœè§£æå¤±è´¥")
                return None, None
        else:
            print(f"âŒ {model_name} è½¬æ¢å­è¿›ç¨‹å¤±è´¥: {result.stderr}")
            return None, None
    except subprocess.TimeoutExpired:
        print(f"âŒ {model_name} è½¬æ¢è¶…æ—¶")
        return None, None
    except Exception as e:
        print(f"âŒ {model_name} è½¬æ¢å¼‚å¸¸: {e}")
        return None, None
    
    # 4. é€šè¿‡å­è¿›ç¨‹è¯„ä¼°TFLiteæ¨¡å‹
    try:
        print(f"ğŸ“Š é€šè¿‡å­è¿›ç¨‹è¯„ä¼° {model_name} TFLiteæ¨¡å‹...")
        result = subprocess.run([
            'python', converter_script, 'evaluate', tflite_path, test_index_path
        ], capture_output=True, text=True, timeout=7200)  # å…¨æµ‹è¯•é›†è¯„ä¼°ï¼Œæœ€å¤§å…è®¸2å°æ—¶
        
        if result.returncode == 0:
            try:
                out = result.stdout.strip()
                last_line = out.splitlines()[-1] if '\n' in out else out
                eval_result = json.loads(last_line)
                if eval_result['success']:
                    print(f"âœ… {model_name} TFLiteè¯„ä¼°æˆåŠŸ")
                    return eval_result['result'], tflite_size_mb
                else:
                    print(f"âŒ {model_name} TFLiteè¯„ä¼°å¤±è´¥: {eval_result['error']}")
                    return None, tflite_size_mb
            except:
                print(f"âŒ {model_name} è¯„ä¼°ç»“æœè§£æå¤±è´¥")
                return None, tflite_size_mb
        else:
            print(f"âŒ {model_name} è¯„ä¼°å­è¿›ç¨‹å¤±è´¥: {result.stderr}")
            return None, tflite_size_mb
    except subprocess.TimeoutExpired:
        print(f"âŒ {model_name} è¯„ä¼°è¶…æ—¶")
        return None, tflite_size_mb
    except Exception as e:
        print(f"âŒ {model_name} è¯„ä¼°å¼‚å¸¸: {e}")
        return None, tflite_size_mb

def evaluate_model_accuracy(model, checkpoint_path, test_loader):
    """è¯„ä¼°æ¨¡å‹ç²¾åº¦"""
    # åŠ è½½æ£€æŸ¥ç‚¹
    if not os.path.exists(checkpoint_path):
        print(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return None
    
    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)
    
    # å°è¯•ä¸åŒçš„çŠ¶æ€å­—å…¸é”®å
    if 'model_state' in checkpoint:
        model.load_state_dict(checkpoint['model_state'])
    elif 'model' in checkpoint:
        model.load_state_dict(checkpoint['model'])
    elif 'state_dict' in checkpoint:
        model.load_state_dict(checkpoint['state_dict'])
    else:
        # å‡è®¾æ•´ä¸ªcheckpointå°±æ˜¯state_dict
        model.load_state_dict(checkpoint)
    
    model = model.to(DEVICE)
    model.eval()
    
    predictions = []
    true_labels = []
    
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(DEVICE)
            outputs = model(images)
            pred = outputs.argmax(1).cpu().numpy()
            
            predictions.extend(pred)
            true_labels.extend(labels.numpy())
    
    accuracy = accuracy_score(true_labels, predictions)
    
    # è·å–æ£€æŸ¥ç‚¹ä¸­çš„è®­ç»ƒä¿¡æ¯
    best_val_acc = checkpoint.get('best_acc', checkpoint.get('best', accuracy))
    epochs = checkpoint.get('epoch', 'Unknown')
    
    return {
        'test_accuracy': accuracy,
        'validation_accuracy': best_val_acc,
        'epochs_trained': epochs,
        'total_samples': len(predictions)
    }

def get_model_size_mb(path):
    return os.path.getsize(path) / (1024 * 1024) if path and os.path.exists(path) else 0.0

def main():
    print("å¼€å§‹æ¨¡å‹è¯„ä¼°...")
    print("="*80)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    processor = DataProcessor()
    master_df = processor.generate_metadata()
    test_df = master_df[master_df['split'] == 'test']
    test_dataset = PlantDataset(test_df, mode='val')  # ä½¿ç”¨valæ¨¡å¼ç¡®ä¿ä¸€è‡´é¢„å¤„ç†
    
    # åˆ›å»ºå•å¼ æ¨ç†çš„æ•°æ®åŠ è½½å™¨ï¼ˆæ¨¡æ‹Ÿç§»åŠ¨ç«¯ï¼‰
    test_loader = torch.utils.data.DataLoader(
        test_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False,
        num_workers=NUM_WORKERS, 
        pin_memory=True
    )
    
    num_classes = len(test_dataset.class_map)
    print(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")
    print(f"ç±»åˆ«æ•°: {num_classes}")
    print(f"ç±»åˆ«æ˜ å°„: {test_dataset.class_map}")
    print()
    
    # ç»“æœå­˜å‚¨
    results = {}
    
    for model_name, checkpoint_path in CHECKPOINTS.items():
        print(f"è¯„ä¼°æ¨¡å‹: {model_name}")
        print("-" * 40)
        
        if not os.path.exists(checkpoint_path):
            print(f"âš ï¸  æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
            print()
            continue
        
        try:
            # åŠ è½½æ¨¡å‹
            model = load_pytorch_model(model_name, num_classes)
            
            # è¯„ä¼°ç²¾åº¦
            print("ğŸ“Š è¯„ä¼°ç²¾åº¦...")
            accuracy_results = evaluate_model_accuracy(model, checkpoint_path, test_loader)
            
            if accuracy_results is None:
                print("âŒ ç²¾åº¦è¯„ä¼°å¤±è´¥")
                continue
            
            # è®¡ç®—æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯
            param_count = count_parameters(model)
            model_size_mb = estimate_model_size_mb(model)
            checkpoint_size_mb = get_checkpoint_size_mb(checkpoint_path)
            
            # æµ‹é‡æ¨ç†æ—¶é—´
            print("â±ï¸  æµ‹é‡æ¨ç†æ—¶é—´...")
            timing_results = measure_inference_time(model, test_loader, num_samples=50)
            
            # æ±‡æ€»PyTorchç»“æœ
            pytorch_metrics = {
                'test_accuracy': accuracy_results['test_accuracy'],
                'validation_accuracy': accuracy_results['validation_accuracy'],
                'epochs_trained': accuracy_results['epochs_trained'],
                'param_count': param_count,
                'model_size_mb': model_size_mb,
                'checkpoint_size_mb': checkpoint_size_mb,
                'inference_time': timing_results
            }
            
            # å­è¿›ç¨‹TFLiteè½¬æ¢ä¸è¯„ä¼°
            tflite_metrics, tflite_size_mb = convert_to_tflite_subprocess(model, model_name, test_loader)
            
            results[model_name] = {
                'pytorch': pytorch_metrics,
                'tflite': tflite_metrics,
                'tflite_size_mb': tflite_size_mb or 0.0
            }
            
            print(f"âœ… {model_name} è¯„ä¼°å®Œæˆ")
            print(f"   æµ‹è¯•ç²¾åº¦: {accuracy_results['test_accuracy']:.4f}")
            print(f"   å‚æ•°é‡: {param_count:,}")
            print(f"   æ¨ç†æ—¶é—´: {timing_results['mean_ms']:.2f}ms")
            print()
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ¨¡å‹ {model_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            print()
            continue
    
    # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
    if not results:
        print("âš ï¸  æ²¡æœ‰æˆåŠŸè¯„ä¼°çš„æ¨¡å‹")
        return
    
    print("\n" + "="*100)
    print("Table 5.5 - TFLiteè½¬æ¢åæ¨¡å‹å¯¹æ¯”")
    print("="*100)
    
    headers = [
        "æ¨¡å‹", 
        "åŸå§‹ç²¾åº¦(%)", "TFLiteç²¾åº¦(%)", "ç²¾åº¦æŸå¤±(%)",
        "åŸå§‹å¤§å°(MB)", "TFLiteå¤§å°(MB)", "å‹ç¼©æ¯”",
        "åŸå§‹å»¶è¿Ÿ(ms)", "TFLiteå»¶è¿Ÿ(ms)", "åŠ é€Ÿæ¯”",
        "å‚æ•°é‡(M)"
    ]
    
    table_data = []
    
    for model_name, result in results.items():
        pytorch_res = result['pytorch']
        tflite_res = result['tflite']
        
        pytorch_acc = pytorch_res['test_accuracy'] * 100
        pytorch_size = pytorch_res['checkpoint_size_mb']
        pytorch_latency = pytorch_res['inference_time']['mean_ms']
        param_count_m = pytorch_res['param_count'] / 1e6

        if tflite_res:
            tflite_acc = tflite_res['accuracy'] * 100
            acc_loss = pytorch_acc - tflite_acc
            tflite_size = result.get('tflite_size_mb', 0.0)
            compression_ratio = (pytorch_size / tflite_size) if tflite_size > 0 else float('inf')
            tflite_latency = tflite_res['avg_inference_time_ms']
            speedup = pytorch_latency / tflite_latency if tflite_latency > 0 else 0.0

            table_data.append([
                model_name,
                f"{pytorch_acc:.2f}",
                f"{tflite_acc:.2f}",
                f"{acc_loss:.2f}",
                f"{pytorch_size:.2f}",
                f"{tflite_size:.2f}",
                f"{compression_ratio:.1f}x" if compression_ratio != float('inf') else "N/A",
                f"{pytorch_latency:.2f}",
                f"{tflite_latency:.2f}",
                f"{speedup:.1f}x" if speedup > 0 else "N/A",
                f"{param_count_m:.2f}"
            ])
        else:
            table_data.append([
                model_name,
                f"{pytorch_acc:.2f}",
                "è½¬æ¢å¤±è´¥",
                "N/A",
                f"{pytorch_size:.2f}",
                "N/A",
                "N/A",
                f"{pytorch_latency:.2f}",
                "N/A",
                "N/A",
                f"{param_count_m:.2f}"
            ])

    print(tabulate(table_data, headers=headers, tablefmt='grid'))

    # ä¿å­˜è¯¦ç»†ç»“æœ
    print("\n" + "="*60)
    print("è¯¦ç»†æ€§èƒ½æŒ‡æ ‡")
    print("="*60)

    for model_name, result in results.items():
        pytorch_res = result['pytorch']
        tflite_res = result['tflite']

        print(f"\n{model_name}:")
        print(f"  åŸå§‹æ¨¡å‹:")
        print(f"    æµ‹è¯•ç²¾åº¦: {pytorch_res['test_accuracy']:.4f}")
        print(f"    éªŒè¯ç²¾åº¦: {pytorch_res['validation_accuracy']:.4f}")
        print(f"    å‚æ•°é‡: {pytorch_res['param_count']:,}")
        print(f"    æ¨¡å‹å¤§å°: {pytorch_res['checkpoint_size_mb']:.2f} MB")
        print(f"    æ¨ç†æ—¶é—´: {pytorch_res['inference_time']['mean_ms']:.2f} Â± {pytorch_res['inference_time']['std_ms']:.2f} ms")
        
        if tflite_res:
            print(f"  TFLiteæ¨¡å‹:")
            print(f"    ç²¾åº¦: {tflite_res['accuracy']:.4f}")
            print(f"    å¤§å°: {result['tflite_size_mb']:.2f} MB")
            print(f"    æ¨ç†æ—¶é—´: {tflite_res['avg_inference_time_ms']:.2f} ms")
            print(f"    ååé‡: {tflite_res['throughput_fps']:.1f} FPS")
            print(f"    æ ·æœ¬æ•°: {tflite_res['total_samples']}")
        else:
            print(f"  TFLiteæ¨¡å‹: è½¬æ¢å¤±è´¥")

    # ä¿å­˜CSVç»“æœ
    csv_data = []
    for model_name, result in results.items():
        pytorch_res = result['pytorch']
        tflite_res = result['tflite']
        
        row = {
            'model_name': model_name,
            'pytorch_test_accuracy': pytorch_res['test_accuracy'],
            'pytorch_validation_accuracy': pytorch_res['validation_accuracy'],
            'pytorch_param_count': pytorch_res['param_count'],
            'pytorch_size_mb': pytorch_res['checkpoint_size_mb'],
            'pytorch_inference_time_ms': pytorch_res['inference_time']['mean_ms'],
            'pytorch_inference_std_ms': pytorch_res['inference_time']['std_ms'],
            'epochs_trained': pytorch_res['epochs_trained']
        }
        
        if tflite_res:
            row.update({
                'tflite_accuracy': tflite_res['accuracy'],
                'tflite_accuracy_ci_low': tflite_res.get('accuracy_ci_low'),
                'tflite_accuracy_ci_high': tflite_res.get('accuracy_ci_high'),
                'tflite_size_mb': result['tflite_size_mb'],
                'tflite_inference_time_ms': tflite_res['avg_inference_time_ms'],
                'tflite_throughput_fps': tflite_res['throughput_fps'],
                'tflite_samples': tflite_res['total_samples'],
                'accuracy_loss': pytorch_res['test_accuracy'] - tflite_res['accuracy'],
                'compression_ratio': pytorch_res['checkpoint_size_mb'] / result['tflite_size_mb'] if result['tflite_size_mb'] > 0 else 0,
                'speedup_ratio': pytorch_res['inference_time']['mean_ms'] / tflite_res['avg_inference_time_ms'] if tflite_res['avg_inference_time_ms'] > 0 else 0
            })
        else:
            row.update({
                'tflite_accuracy': None,
                'tflite_size_mb': None,
                'tflite_inference_time_ms': None,
                'tflite_throughput_fps': None,
                'tflite_samples': None,
                'accuracy_loss': None,
                'compression_ratio': None,
                'speedup_ratio': None
            })
        
        csv_data.append(row)
    
    df = pd.DataFrame(csv_data)
    df.to_csv('model_tflite_comparison_results.csv', index=False)
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: model_tflite_comparison_results.csv")

if __name__ == "__main__":
    main()